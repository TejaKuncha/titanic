{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load modules\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "print('Load modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "t0 = time()\n",
    "data = pd.read_csv('train.csv')\n",
    "label = data['Survived']\n",
    "data = data.drop(['Name', 'Ticket', 'Cabin', 'Survived', 'PassengerId'], axis=1)\n",
    "\n",
    "data['Age'] = data['Age'].fillna(np.nanmean(data['Age']))        # Assign mean\n",
    "data['Fare'] = data['Fare'].fillna(np.nanmean(data['Fare']))     # Assign mean\n",
    "data['Embarked'] = data['Embarked'].fillna('U')\n",
    "label_enc = LabelEncoder()\n",
    "data['Sex'] = label_enc.fit_transform(data['Sex'])\n",
    "data['Embarked'] = label_enc.fit_transform(data['Embarked'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape =  (712, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(data, label, test_size=0.2)\n",
    "print('X_train_shape = ', X_train.shape)\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_valid = scale.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='poly', degree=6, coef0=1, C=1, probability=True)\n",
    "ada_svm = AdaBoostClassifier(base_estimator=svm, n_estimators=100, algorithm='SAMME', learning_rate=1)\n",
    "bag_svm = BaggingClassifier(base_estimator=svm, n_estimators=100)\n",
    "\n",
    "nbr = KNeighborsClassifier(n_neighbors=11, weights='distance', p=1)\n",
    "bag_knn = BaggingClassifier(base_estimator=nbr, n_estimators=100)\n",
    "\n",
    "neu = MLPClassifier(hidden_layer_sizes=(300, 75), activation='logistic', solver='lbfgs', alpha=0.001, early_stopping=True)\n",
    "bag_neu = BaggingClassifier(base_estimator=neu, n_estimators=100)\n",
    "\n",
    "dec = DecisionTreeClassifier(class_weight='balanced')\n",
    "ada_dec = AdaBoostClassifier(base_estimator=dec, n_estimators=50, algorithm='SAMME.R', learning_rate=0.001)\n",
    "bag_dec = BaggingClassifier(base_estimator=dec, n_estimators=150)\n",
    "rad = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "classifiers = {'Std SVM': svm, 'Std KNN': nbr, 'Std MLP': neu, 'Std DTL': dec, 'Std RTr': rad, \n",
    "               'Bag SVM': bag_svm, 'Bag KNN': bag_knn, 'Bag MLP': bag_neu, 'Bag DTL': bag_dec, \n",
    "               'Ada SVM': ada_svm, 'ADA DTL': ada_dec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std SVM\tAcc = 0.8268\tf-score = 0.7597\tlog_loss = 0.4416\n",
      "Std KNN\tAcc = 0.8324\tf-score = 0.7794\tlog_loss = 1.7082\n",
      "Std MLP\tAcc = 0.8101\tf-score = 0.7344\tlog_loss = 0.4367\n",
      "Std DTL\tAcc = 0.7542\tf-score = 0.7067\tlog_loss = 8.1348\n",
      "Std RTr\tAcc = 0.8324\tf-score = 0.7887\tlog_loss = 0.8019\n",
      "Bag SVM\tAcc = 0.8268\tf-score = 0.7597\tlog_loss = 0.4339\n",
      "Bag KNN\tAcc = 0.8324\tf-score = 0.7794\tlog_loss = 0.6551\n",
      "Bag MLP\tAcc = 0.8324\tf-score = 0.7581\tlog_loss = 0.3893\n",
      "Bag DTL\tAcc = 0.8380\tf-score = 0.7972\tlog_loss = 0.9666\n",
      "Ada SVM\tAcc = 0.7989\tf-score = 0.7313\tlog_loss = 0.5800\n",
      "ADA DTL\tAcc = 0.7709\tf-score = 0.7172\tlog_loss = 6.1226\n"
     ]
    }
   ],
   "source": [
    "for name in classifiers:\n",
    "    clf = classifiers[name]\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pro = clf.predict_proba(X_valid)\n",
    "    y_ = (y_pro[:, 1] > 0.51)\n",
    "    loss = log_loss(y_valid, y_pro)\n",
    "    acc = accuracy_score(y_valid, y_)\n",
    "    fsc = f1_score(y_valid, y_)\n",
    "    print('%s\\tAcc = %0.4f\\tf-score = %0.4f\\tlog_loss = %0.4f' %((name, acc, fsc, loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] n_estimators=25 .................................................\n",
      "[CV] ........ n_estimators=25, score=0.7857142857142857, total=   0.0s\n",
      "[CV] n_estimators=25 .................................................\n",
      "[CV] ......... n_estimators=25, score=0.810126582278481, total=   0.0s\n",
      "[CV] n_estimators=25 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ n_estimators=25, score=0.8354430379746836, total=   0.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ......... n_estimators=50, score=0.773109243697479, total=   0.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ......... n_estimators=50, score=0.810126582278481, total=   0.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........ n_estimators=50, score=0.8354430379746836, total=   0.0s\n",
      "[CV] n_estimators=75 .................................................\n",
      "[CV] ........ n_estimators=75, score=0.7857142857142857, total=   0.0s\n",
      "[CV] n_estimators=75 .................................................\n",
      "[CV] ......... n_estimators=75, score=0.810126582278481, total=   0.0s\n",
      "[CV] n_estimators=75 .................................................\n",
      "[CV] ........ n_estimators=75, score=0.8312236286919831, total=   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ........ n_estimators=100, score=0.773109243697479, total=   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....... n_estimators=100, score=0.8143459915611815, total=   0.1s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ....... n_estimators=100, score=0.8143459915611815, total=   0.1s\n",
      "[CV] n_estimators=125 ................................................\n",
      "[CV] ....... n_estimators=125, score=0.7773109243697479, total=   0.1s\n",
      "[CV] n_estimators=125 ................................................\n",
      "[CV] ....... n_estimators=125, score=0.8143459915611815, total=   0.1s\n",
      "[CV] n_estimators=125 ................................................\n",
      "[CV] ....... n_estimators=125, score=0.8396624472573839, total=   0.1s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ....... n_estimators=150, score=0.7773109243697479, total=   0.2s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ........ n_estimators=150, score=0.810126582278481, total=   0.2s\n",
      "[CV] n_estimators=150 ................................................\n",
      "[CV] ....... n_estimators=150, score=0.8354430379746836, total=   0.2s\n",
      "[CV] n_estimators=175 ................................................\n",
      "[CV] ........ n_estimators=175, score=0.773109243697479, total=   0.2s\n",
      "[CV] n_estimators=175 ................................................\n",
      "[CV] ........ n_estimators=175, score=0.810126582278481, total=   0.2s\n",
      "[CV] n_estimators=175 ................................................\n",
      "[CV] ....... n_estimators=175, score=0.8354430379746836, total=   0.2s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ....... n_estimators=200, score=0.7647058823529411, total=   0.4s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ....... n_estimators=200, score=0.8143459915611815, total=   0.2s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ....... n_estimators=200, score=0.8354430379746836, total=   0.3s\n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.050003         0.003667         0.810393          0.986658   \n",
      "1       0.096005         0.006667         0.806180          0.989466   \n",
      "2       0.136341         0.009667         0.808989          0.990170   \n",
      "3       0.153342         0.011667         0.800562          0.990170   \n",
      "4       0.200678         0.016001         0.810393          0.990170   \n",
      "5       0.297684         0.020001         0.807584          0.990170   \n",
      "6       0.302350         0.021668         0.806180          0.990170   \n",
      "7       0.379355         0.021335         0.804775          0.990170   \n",
      "\n",
      "  param_n_estimators                 params  rank_test_score  \\\n",
      "0                 25   {'n_estimators': 25}                1   \n",
      "1                 50   {'n_estimators': 50}                5   \n",
      "2                 75   {'n_estimators': 75}                3   \n",
      "3                100  {'n_estimators': 100}                8   \n",
      "4                125  {'n_estimators': 125}                1   \n",
      "5                150  {'n_estimators': 150}                4   \n",
      "6                175  {'n_estimators': 175}                5   \n",
      "7                200  {'n_estimators': 200}                7   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.785714            0.987342           0.810127   \n",
      "1           0.773109            0.989451           0.810127   \n",
      "2           0.785714            0.991561           0.810127   \n",
      "3           0.773109            0.991561           0.814346   \n",
      "4           0.777311            0.991561           0.814346   \n",
      "5           0.777311            0.991561           0.810127   \n",
      "6           0.773109            0.991561           0.810127   \n",
      "7           0.764706            0.991561           0.814346   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.987368           0.835443            0.985263      0.012755   \n",
      "1            0.989474           0.835443            0.989474      0.006481   \n",
      "2            0.989474           0.831224            0.989474      0.005437   \n",
      "3            0.989474           0.814346            0.989474      0.003399   \n",
      "4            0.989474           0.839662            0.989474      0.017328   \n",
      "5            0.989474           0.835443            0.989474      0.040797   \n",
      "6            0.989474           0.835443            0.989474      0.025696   \n",
      "7            0.989474           0.835443            0.989474      0.060953   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000471        0.020310         0.000986  \n",
      "1        0.000472        0.025609         0.000010  \n",
      "2        0.000943        0.018603         0.000984  \n",
      "3        0.000943        0.019453         0.000984  \n",
      "4        0.004243        0.025616         0.000984  \n",
      "5        0.002160        0.023808         0.000984  \n",
      "6        0.002494        0.025609         0.000984  \n",
      "7        0.000471        0.029669         0.000984  \n",
      "{'n_estimators': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    5.6s finished\n"
     ]
    }
   ],
   "source": [
    "param = {'n_estimators': [25, 50, 75, 100, 125, 150]}\n",
    "grid = GridSearchCV(rad, param, cv=3, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(pd.DataFrame(grid.cv_results_ ))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
